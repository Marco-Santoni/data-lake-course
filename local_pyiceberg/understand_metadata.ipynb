{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda install pyiceberg\n",
    "conda install sqlalchemy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "table_dir = \"iceberg_warehouse\"\n",
    "\n",
    "if os.path.exists(table_dir):\n",
    "    shutil.rmtree(table_dir)\n",
    "\n",
    "os.makedirs(table_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of demonstration, we'll configure the catalog to use the SqlCatalog implementation, which will store information in a local sqlite database. We'll also configure the catalog to store data files in the local filesystem instead of an object store. This should not be used in production due to the limited scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog.sql import SqlCatalog\n",
    "\n",
    "warehouse_path = os.path.abspath(\"./iceberg_warehouse\")\n",
    "catalog = SqlCatalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"uri\": f\"sqlite:///{warehouse_path}/pyiceberg_catalog.db\",\n",
    "        \"warehouse\": f\"file://{warehouse_path}\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyiceberg.catalog import Catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import NestedField, StringType, LongType\n",
    "from pyiceberg.table import Table\n",
    "from pyiceberg.io import FileIO\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Apache Iceberg is an open table format for huge analytic datasets. It is designed to improve on the\n",
    "# performance and usability of existing table formats like Hive, Hudi, and Delta Lake.\n",
    "\n",
    "# PyIceberg is a Python library for interacting with Apache Iceberg tables.\n",
    "\n",
    "# In this tutorial, we will understand the metadata files of Apache Iceberg using PyIceberg and local files only.\n",
    "\n",
    "\n",
    "# Step 2: Create a local directory for the Iceberg table\n",
    "\n",
    "table_dir = \"iceberg_table\"\n",
    "os.makedirs(table_dir, exist_ok=True)\n",
    "\n",
    "# Step 3: Initialize an Iceberg table\n",
    "\n",
    "# Define the schema for the table\n",
    "schema = Schema(\n",
    "    NestedField(field_id=1, name=\"id\", field_type=LongType(), required=False),\n",
    "    NestedField(field_id=1, name=\"name\", field_type=StringType(), required=False)\n",
    ")\n",
    "\n",
    "# Create a catalog and table\n",
    "table = catalog.create_table(\"default.my_table\", schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our first metadata file.\n",
    "\n",
    "Now, we can write data to table. PyIceberg is nicely integrated with PyArrow. We create an Arrow table and append it to the Iceberg table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "id: int64\n",
       "name: string\n",
       "----\n",
       "id: [[1,2]]\n",
       "name: [[\"Alice\",\"Bob\"]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "# Step 4: Add some data to the table\n",
    "\n",
    "# Define some data\n",
    "data = [\n",
    "    {\"id\": 1, \"name\": \"Alice\"},\n",
    "    {\"id\": 2, \"name\": \"Bob\"}\n",
    "]\n",
    "# Create a PyArrow Table from the list of dictionaries\n",
    "arrow_table = pa.Table.from_pylist(data)\n",
    "\n",
    "# Write the data to the table\n",
    "arrow_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Table.identifier property is deprecated. Please use Table.name() function instead.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n",
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Support for parsing catalog level identifier in Catalog identifiers is deprecated. Please refer to the table using only its namespace and its table name.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n",
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Table.identifier property is deprecated. Please use Table.name() function instead.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n"
     ]
    }
   ],
   "source": [
    "table.append(arrow_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at metadata folder.\n",
    "\n",
    "We start from the manifest list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'manifest_path': 'file:///Users/marcosantoni/Desktop/data-lake-course/local_pyiceberg/iceberg_warehouse/default.db/my_table/metadata/e771a111-380e-49db-bb65-5420db7d0c90-m0.avro', 'manifest_length': 4367, 'partition_spec_id': 0, 'content': 0, 'sequence_number': 1, 'min_sequence_number': 1, 'added_snapshot_id': 3096979458630272547, 'added_files_count': 1, 'existing_files_count': 0, 'deleted_files_count': 0, 'added_rows_count': 2, 'existing_rows_count': 0, 'deleted_rows_count': 0, 'partitions': [], 'key_metadata': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "metadata_folder = './iceberg_warehouse/default.db/my_table/metadata'\n",
    "\n",
    "reader = DataFileReader(open(os.path.join(metadata_folder, 'snap-3096979458630272547-0-e771a111-380e-49db-bb65-5420db7d0c90.avro'), \"rb\"), DatumReader())\n",
    "for user in reader:\n",
    "    # a generator to loop over dictionaries\n",
    "    print(user)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then look at the actual manifest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 1, 'snapshot_id': 3096979458630272547, 'sequence_number': None, 'file_sequence_number': None, 'data_file': {'content': 0, 'file_path': 'file:///Users/marcosantoni/Desktop/data-lake-course/local_pyiceberg/iceberg_warehouse/default.db/my_table/data/00000-0-e771a111-380e-49db-bb65-5420db7d0c90.parquet', 'file_format': 'PARQUET', 'partition': {}, 'record_count': 2, 'file_size_in_bytes': 915, 'column_sizes': [{'key': 1, 'value': 118}, {'key': 2, 'value': 90}], 'value_counts': [{'key': 1, 'value': 2}, {'key': 2, 'value': 2}], 'null_value_counts': [{'key': 1, 'value': 0}, {'key': 2, 'value': 0}], 'nan_value_counts': [], 'lower_bounds': [{'key': 1, 'value': b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00'}, {'key': 2, 'value': b'Alice'}], 'upper_bounds': [{'key': 1, 'value': b'\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00'}, {'key': 2, 'value': b'Bob'}], 'key_metadata': None, 'split_offsets': [4], 'equality_ids': None, 'sort_order_id': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/avro/schema.py:1233: IgnoredLogicalType: Unknown map, using array.\n",
      "  warnings.warn(avro.errors.IgnoredLogicalType(f\"Unknown {logical_type}, using {type_}.\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "metadata_folder = './iceberg_warehouse/default.db/my_table/metadata'\n",
    "\n",
    "reader = DataFileReader(open(os.path.join(metadata_folder, 'e771a111-380e-49db-bb65-5420db7d0c90-m0.avro'), \"rb\"), DatumReader())\n",
    "for user in reader:\n",
    "    # a generator to loop over dictionaries\n",
    "    print(user)\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/avro/decoder.py:185: UserWarning: Falling back to pure Python Avro decoder, missing Cython implementation\n",
      "  warnings.warn(\"Falling back to pure Python Avro decoder, missing Cython implementation\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Table.identifier property is deprecated. Please use Table.name() function instead.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n",
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Support for parsing catalog level identifier in Catalog identifiers is deprecated. Please refer to the table using only its namespace and its table name.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n",
      "/Users/marcosantoni/miniconda3/envs/data_file_formats/lib/python3.12/site-packages/pyiceberg/utils/deprecated.py:54: DeprecationWarning: Deprecated in 0.8.0, will be removed in 0.9.0. Table.identifier property is deprecated. Please use Table.name() function instead.\n",
      "  _deprecation_warning(deprecation_notice(deprecated_in, removed_in, help_message))\n"
     ]
    }
   ],
   "source": [
    "# Define some data\n",
    "data = [\n",
    "    {\"id\": 3, \"name\": \"Daniel\"}\n",
    "]\n",
    "# Create a PyArrow Table from the list of dictionaries\n",
    "arrow_table = pa.Table.from_pylist(data)\n",
    "table.append(arrow_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite some extra stuff in the `data` and `metadata` folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_file_formats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
